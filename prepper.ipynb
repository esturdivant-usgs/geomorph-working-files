{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process input data for coastal variable extraction\n",
    "\n",
    "Author: Emily Sturdivant; esturdivant@usgs.gov\n",
    "\n",
    "***\n",
    "\n",
    "Pre-process files to be used in extractor.ipynb (Extract barrier island metrics along transects). See the project [README](https://github.com/esturdivant-usgs/BI-geomorph-extraction/blob/master/README.md) and the Methods Report (Zeigler et al., in review). \n",
    "\n",
    "\n",
    "## Pre-processing steps\n",
    "\n",
    "1. Pre-created geomorphic features: dunes, shoreline points, armoring.\n",
    "2. Inlets\n",
    "3. Shoreline\n",
    "4. Transects - extend and sort\n",
    "5. Transects - tidy\n",
    "\n",
    "\n",
    "## Notes:\n",
    "This process requires some manipulation of the spatial layers by the user. When applicable, instructions are described in this file.\n",
    "\n",
    "***\n",
    "\n",
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arcpy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "try:\n",
    "    import core.functions_warcpy as fwa\n",
    "    import core.functions as fun\n",
    "except ImportError as err:\n",
    "    print(\"Looks like you need to install the module to your ArcGIS environment. Please see the README for details.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables\n",
    "\n",
    "Change the filename variables to match your local files. They should be in an Esri file geodatabase named site+year.gdb in your project directory, which will be the value of the variable `home`. \n",
    "\n",
    "Input the site, year, and project directory path. `setvars.py` retrieves the pre-determined values for that site in that year from `configmap.py`. The project directory will be used to set up your workspace. It's hidden for security â€“ sorry! I recommend that you type the path somewhere and paste it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site: Rockaway\n",
      "year: 2014\n",
      "Path to project directory (e.g. \\\\Mac\u000b",
      "olume\\dir\\FireIsland2014): \\\\Mac\\stor\\Projects\\TransectExtraction\\Rockaway2014\n"
     ]
    }
   ],
   "source": [
    "from core.setvars import *\n",
    "\n",
    "# Inputs - vector\n",
    "orig_trans = os.path.join(arcpy.env.workspace, 'DelmarvaS_SVA_LT')\n",
    "ShorelinePts = os.path.join(home, 'SLpts')\n",
    "dlPts = os.path.join(home, 'DLpts')\n",
    "dhPts = os.path.join(home, 'DHpts')\n",
    "# Inputs - raster\n",
    "elevGrid = os.path.join(home, 'DEM')\n",
    "elevGrid_5m = os.path.join(home, 'DEM_5m')\n",
    "SubType = os.path.join(home, 'FI11_SubType')\n",
    "VegType = os.path.join(home, 'FI11_VegType')\n",
    "VegDens = os.path.join(home, 'FI11_VegDens')\n",
    "GeoSet = os.path.join(home, 'FI11_GeoSet')\n",
    "DisMOSH = os.path.join(home, 'FI11_DisMOSH')\n",
    "\n",
    "# Files to create or modify\n",
    "armorLines = os.path.join(home, 'armorLines')\n",
    "inletLines = os.path.join(home, 'inletLines')\n",
    "SA_bounds = 'SA_bounds'\n",
    "\n",
    "# Outputs\n",
    "extendedTrans = os.path.join(home, 'extTrans')\n",
    "extTrans_tidy = os.path.join(home, 'tidyTrans')\n",
    "barrierBoundary = os.path.join(home, 'bndpoly_2sl')  \n",
    "shoreline = os.path.join(home, 'ShoreBetweenInlets')\n",
    "\n",
    "tr_w_anthro = os.path.join(home, 'extTrans_wAnthro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare input layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapre = '14CNT01'\n",
    "csvpath = os.path.join(proj_dir, 'Input_Data', '{}_morphology'.format(datapre), '{}_morphology.csv'.format(datapre))\n",
    "\n",
    "# state = sitevals['state']\n",
    "dt_fc, dc_fc, sl_fc = fwa.MorphologyCSV_to_FCsByFeature(csvpath, state, proj_code, csv_fill = 999, fc_fill = -99999, csv_epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dunes\n",
    "Display the points and the DEM in a GIS to check for irregularities. For example, if shoreline points representing a distance less than X m are visually offset from the general shoreline, they should likely be removed. Another red flag is when the positions of dlows and dhighs in relation to the shore are illogical, i.e. dune crests are seaward of dune toes. Address these irregularities by manually deleting points. Delete conservatively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armoring\n",
    "If the dlows do not capture the entire top-of-beach due to atypical formations caused by anthropogenic modification, you may need to digitize the beachfront armoring. The next code block will generate an empty feature class. Refer to the DEM and orthoimagery. If there is no armoring in the study area, continue. If there is armoring, use the Editing toolbar to add lines to the feature class that trace instances of armoring. Common manifestations of what we call armoring are sandfencing and sandbagging and concrete seawalls. \n",
    "\n",
    "If there is no armoring file in the project geodatabase, the extractor script will notify you that it is proceeding without armoring.\n",
    "\n",
    "*__Requires manipulation in GIS__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arcpy.CreateFeatureclass_management(home, os.path.basename(armorLines), 'POLYLINE', spatial_reference=utmSR)\n",
    "print(\"{} created. Now manually digitize the shorefront armoring.\".format(armorLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inlets\n",
    "We also need to manually digitize inlets if an inlet delineation does not already exist. To do, the code below will produce the feature class. After which, use the Editing toolbar to create a line where the oceanside shore meets a tidal inlet. If the study area includes both sides of an inlet, that inlet will be represented by two lines. The inlet lines are use to define the bounds of the oceanside shore, which is also considered the point where the oceanside shore meets the bayside. Inlet lines must intersect the MHW contour. \n",
    "\n",
    "What do we do when the study area and not an inlet is the end?\n",
    "\n",
    "*__Requires manipulation in GIS__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# manually create lines that correspond to end of land and cross the MHW line (use bndpoly/DEM)\n",
    "arcpy.CreateFeatureclass_management(home, os.path.basename(inletLines), 'POLYLINE', spatial_reference=utmSR)\n",
    "print(\"{} created. Now we'll stop for you to manually create lines at each inlet.\".format(inletLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shoreline\n",
    "The shoreline is produced through a combination of the DEM and the shoreline points. The first step converts the DEM to both MTL and MHW contour polygons. Those polygons are combined to produce the full shoreline, which is considered to fall at MHW on the oceanside and MTL on the bayside (to include partially submerged wetland).\n",
    "\n",
    "If the study area does not end cleanly at an inlet, create a separate polyline feature class (default name is 'SA_bounds') and add lines that bisect the shoreline; they should look and function like inlet lines. Specify this in the arguments for DEMtoFullShorelinePoly() and CreateShoreBetweenInlets().\n",
    "\n",
    "At some small inlets, channel depth may be above MTL. In this case, the script left to its own devices will leave the MTL contour between the two inlet lines. This can be rectified after processing by deleting the mid-inlet features from the temp file 'shore_2split.' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\Mac\\stor\\Projects\\TransectExtraction\\Rockaway2014\\Rockaway2014.gdb\\SA_bounds created. Now we'll stop for you to manually create lines at each inlet.\n"
     ]
    }
   ],
   "source": [
    "# manually create lines that correspond to end of land and cross the MHW line (use bndpoly/DEM)\n",
    "if len(SA_bounds) and not arcpy.Exists(SA_bounds):\n",
    "    arcpy.CreateFeatureclass_management(home, 'SA_bounds', 'POLYLINE', spatial_reference=utmSR)\n",
    "print(\"{} created. \\nNow we'll stop for you to manually create lines at each inlet.\".format(SA_bounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the MTL contour polgon from the DEM...\n",
      "Creating the MHW contour polgon from the DEM...\n",
      "Combining the two polygons...\n",
      "Isolating the above-MTL portion of the polygon to the bayside...\n",
      "\n",
      "User input required! Select extra features in bndpoly for deletion.\n",
      "\n",
      "        Recommended technique: select the polygon/s to keep and then Switch Selection.\n",
      "\n",
      "Select features from bndpoly that should not be included in the final shoreline polygon. \n"
     ]
    }
   ],
   "source": [
    "bndpoly = fwa.DEMtoFullShorelinePoly(elevGrid_5m, sitevals['MTL'], sitevals['MHW'], inletLines, ShorelinePts)\n",
    "print('Select features from {} that should not be included in the final shoreline polygon. '.format(bndpoly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Requires display in GIS__*\n",
    "\n",
    "User input is required to identify only the areas within the study area and eliminate isolated landmasses that are not. Once the features to delete are selected, either delete in the GIS or run the code below. Make sure the bndpoly variable matches the layer name in the GIS.\n",
    "\n",
    "__Do not...__ select the features in ArcGIS and then run DeleteFeatures in this Notebook Python kernel. That will delete the entire feature class. \n",
    "\n",
    "```\n",
    "arcpy.DeleteFeatures_management(bndpoly)\n",
    "```\n",
    "\n",
    "The next step snaps the boundary polygon to the shoreline points anywhere they don't already match and as long as as they are within 25 m of each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: \\\\Mac\\stor\\Projects\\TransectExtraction\\Rockaway2014\\Rockaway2014.gdb\\bndpoly_2sl\n"
     ]
    }
   ],
   "source": [
    "barrierBoundary = fwa.NewBNDpoly(bndpoly, ShorelinePts, barrierBoundary, '25 METERS', '50 METERS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ShoreBetweenInlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The projection of \\\\Mac\\stor\\Projects\\TransectExtraction\\Rockaway2014\\Rockaway2014.gdb\\bndpoly_2sl was changed. The new file is \\\\Mac\\stor\\Projects\\TransectExtraction\\Rockaway2014\\Rockaway2014.gdb\\bndpoly_2sl_utm.\n",
      "Splitting \\\\Mac\\stor\\Projects\\TransectExtraction\\Rockaway2014\\Rockaway2014.gdb\\bndpoly_2sl_utm at inlets...\n",
      "Preserving only those line segments that intersect shoreline points...\n",
      "Dissolving the line to create \\\\Mac\\stor\\Projects\\TransectExtraction\\Rockaway2014\\Rockaway2014.gdb\\ShoreBetweenInlets...\n"
     ]
    }
   ],
   "source": [
    "# This step could be moved out of pre-processing and into the extractor because it doesn't require user input.\n",
    "shoreline = fwa.CreateShoreBetweenInlets(barrierBoundary, inletLines, shoreline, \n",
    "                                         ShorelinePts, proj_code, SA_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transects - extend, sort, and tidy\n",
    "\n",
    "Create extendedTrans, which are NASC transects for the study area extended to cover the island, with gaps filled, and sorted in the field sort_ID.\n",
    "\n",
    "#### 1. Extend the transects and use a copy of the lines to fill alongshore gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to remove extra transects? 'y' if barrierBoundary should be used to select. n\n",
      "\\\\Mac\\stor\\Projects\\TransectExtraction\\Rockaway2014\\Rockaway2014.gdb\\origTrans is already projected in UTM.\n",
      "Transects extended.\n",
      "MANUALLY: use groups of existing transects in new FC '\\\\Mac\\stor\\Projects\\TransectExtraction\\Rockaway2014\\scratch.gdb\\trans_presort_temp' to fill gaps.\n"
     ]
    }
   ],
   "source": [
    "# Initialize temp file names\n",
    "trans_extended = os.path.join(arcpy.env.scratchGDB, 'trans_extended')\n",
    "trans_presort = trans_extended+'_presort'\n",
    "\n",
    "# Delete transects over 200 m outside of the study area.\n",
    "if input(\"Need to remove extra transects? 'y' if barrierBoundary should be used to select. \") == 'y':\n",
    "    fwa.RemoveTransectsOutsideBounds(orig_trans, barrierBoundary)\n",
    "\n",
    "# Extend transects and create blank duplicate to use to fill gaps\n",
    "fwa.ExtendLine(orig_trans, trans_extended, extendlength, proj_code)\n",
    "fwa.CopyAndWipeFC(trans_extended, trans_presort, ['sort_ID'])\n",
    "print(\"MANUALLY: use groups of existing transects in new FC '{}' to fill gaps.\".format(trans_presort))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Requires manipulation in GIS__*\n",
    "\n",
    "1. Edit the trans_presort_temp feature class. __Move and rotate__ groups of transects to fill in gaps that are greater than 50 m alongshore. There is no need to preserve the original transects, but avoid overlapping the transects with each other and with the originals. Do not move any transects slightly. If they are moved, they will not be deleted in the next stage. If you slightly move any, you can either undo or delete that line entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\Mac\\stor\\Projects\\TransectExtraction\\Rockaway2014\\scratch.gdb\\trans_presort_temp ready for sorting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\\\\\Mac\\\\stor\\\\Projects\\\\TransectExtraction\\\\Rockaway2014\\\\scratch.gdb\\\\trans_presort_temp'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fwa.RemoveDuplicates(trans_presort, trans_extended, barrierBoundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Sort the transects along the shore\n",
    "Usually if the shoreline curves, we need to identify different groups of transects for sorting. This is because the GIS will not correctly establish the alongshore order by simple ordering from the identified sort_corner. If this is the case, answer __yes__ to the next prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do we need to sort the transects in batches to preserve the order? (y/n) n\n",
      "Sort corner (LL, LR, UL, UR): LL\n"
     ]
    }
   ],
   "source": [
    "sort_lines = fwa.SortTransectPrep(spatialref=utmSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Requires manipulation in GIS__*\n",
    "\n",
    "The last step generated an empty sort lines feature class if you indicated that transects need to be sorted in batches to preserve the order. Now, the user creates lines that will be used to spatially sort transects in groups. \n",
    "\n",
    "For each group of transects:\n",
    "\n",
    "1. __Create a new line__ in 'sort_lines' that intersects all transects in the group. The transects intersected by the line will be sorted independently before being appended to the preceding groups.  (*__add example figure__*)\n",
    "2. __Assign values__ for the fields 'sort,' 'sort_corner,' and 'reverse.' 'sort' indicates the order in which the line should be used and 'sort_corn' indicates the corner from which to perform the spatial sort ('LL', 'UL', etc.). 'reverse' indicates whether the order should be reversed (roughly equivalent to 'DESCENDING').\n",
    "3. Run the following code to create a new sorted transect file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fwa.SortTransectsFromSortLines(trans_presort, extendedTrans, sort_lines, tID_fld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tidy the extended (and sorted) transects to remove overlap\n",
    "\n",
    "*__Requires manipulation in GIS__*\n",
    "\n",
    "Overlapping transects cause problems during conversion to 5-m points and to rasters. We create a separate feature class with the 'tidied' transects, in which the lines don't overlap. This is largely a manually process with the following steps:\n",
    "\n",
    "1. Select transects to be used to split other transects. Prioritize transects that a) were originally from NASC, b) have dune points within 25 m, and c) are oriented perpendicular to shore. (add example figure)\n",
    "2. Use the Copy Features geoprocessing tool to copy only the selected transects into a new feature class. If desired, here is the code that could be used to copy the selected features and clear the selection:\n",
    "```python\n",
    "arcpy.CopyFeatures_management(extendedTrans, overlapTrans_lines)\n",
    "arcpy.SelectLayerByAttribute_management(extendedTrans, \"CLEAR_SELECTION\")\n",
    "```\n",
    "3. Run the code below to split the transects at the selected lines of overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overlapTrans_lines = os.path.join(arcpy.env.scratchGDB, 'overlapTrans_lines')\n",
    "if not arcpy.Exists(overlapTrans_lines):\n",
    "    overlapTrans_lines = input(\"Filename of the feature class of only 'boundary' transects: \")\n",
    "arcpy.Intersect_analysis([extendedTrans, overlapTrans_lines], trans_x,\n",
    "                         'ALL', output_type=\"POINT\")\n",
    "arcpy.SplitLineAtPoint_management(extendedTrans, trans_x, extTrans_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the extraneous segments manually. Recommended:\n",
    "\n",
    "1. Using Select with Line draw a line to the appropriate side of the boundary transects. This will select the line segments that need to be deleted.\n",
    "1. Delete the selected lines.\n",
    "1. Remove any remaining overlaps entirely by hand. Use the Split Line tool in the Editing toolbar to split lines to be shortened at the points of overlap. Then delete the remnant sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join anthro data to transects\n",
    "\n",
    "1. Convert xls spreadsheet to points \n",
    "2. Select the first points along each transects and create new FC\n",
    "3. Spatial Join the new FC to the updated transects \n",
    "    - one to one\n",
    "    - keep all target features\n",
    "    - keep only the ID fields and the three anthro fields (and the transect fields [LRR, etc.]?)\n",
    "    - intersect\n",
    "\n",
    "4. Join the transect values to the pts based on sort_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Input shapefiles\n",
    "shlpts_shp = os.path.join(proj_dir, 'rock14_shlpts.shp')\n",
    "dlpts_shp = os.path.join(proj_dir, 'rock14_dlowpts.shp')\n",
    "dhpts_shp = os.path.join(proj_dir, 'rock14_dhighpts.shp')\n",
    "trans_shp = os.path.join(proj_dir, 'rock_trans.shp')\n",
    "shoreline_shp = os.path.join(proj_dir, 'rock14_shoreline.shp')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
