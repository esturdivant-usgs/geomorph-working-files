{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arcpy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import core.functions_warcpy as fwa\n",
    "import core.functions as fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site (options: Forsythe, Parramore, Assateague, Fisherman, Smith, ParkerRiver, FireIsland, Cedar, Cobb, CapeLookout, CoastGuard, Monomoy, Rockaway): Cobb\n",
      "year (options: 2010, 2012, 2014): 2014\n",
      "Path to project directory (e.g. \\\\Mac\u000b",
      "olume\\dir\\FireIsland2014): ········\n",
      "setvars.py initialized variables.\n"
     ]
    }
   ],
   "source": [
    "from core.setvars import *\n",
    "\n",
    "extendedTrans = os.path.join(home, 'fiis_trans')\n",
    "extTrans_tidy = os.path.join(home, 'tidyTrans')\n",
    "\n",
    "inletLines = os.path.join(home, 'inletLines')\n",
    "ShorelinePts = os.path.join(home, 'SLpts_utm')\n",
    "dlPts = os.path.join(home, 'DLpts_utm')\n",
    "dhPts = os.path.join(home, 'DHpts_utm')\n",
    "armorLines = os.path.join(home, 'armorLines')\n",
    "elevGrid = os.path.join(home, 'DEM')\n",
    "elevGrid_5m = os.path.join(home, 'DEM_5m')\n",
    "barrierBoundary = os.path.join(home, 'bndpoly_2sl')  \n",
    "shoreline = os.path.join(home, 'ShoreBetweenInlets')\n",
    "\n",
    "SubType = os.path.join(home, 'FI12_SubType')\n",
    "VegType = os.path.join(home, 'FI12_VegType')\n",
    "VegDens = os.path.join(home, 'FI12_VegDen')\n",
    "GeoSet = os.path.join(home, 'FI12_GeoSet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge from excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Import data from xls \n",
    "# File name\n",
    "xls_path = r\"\\\\IGSAGIEGGS-CSGG\\Thieler_Group\\Commons_DeepDive\\DeepDive\\NewYork\\AnthropogenicData\"\n",
    "xls_name = \"FI2012_trans_5mPtsUpCombinedsubFixALL2.xlsx\"\n",
    "\n",
    "xltbl = pd.read_excel(os.path.join(xls_path, xls_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID_1</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>BASELINEID</th>\n",
       "      <th>TRANSORDER</th>\n",
       "      <th>PROCTIME</th>\n",
       "      <th>AUTOGEN</th>\n",
       "      <th>ENDX</th>\n",
       "      <th>ENDY</th>\n",
       "      <th>AZIMUTH</th>\n",
       "      <th>SHAPE_LENG</th>\n",
       "      <th>...</th>\n",
       "      <th>Dist_MHWbay</th>\n",
       "      <th>SplitSort</th>\n",
       "      <th>DistSegDH</th>\n",
       "      <th>DistSegDL</th>\n",
       "      <th>DistSegArm</th>\n",
       "      <th>PointZ</th>\n",
       "      <th>PointSlp</th>\n",
       "      <th>Development</th>\n",
       "      <th>Nourishment</th>\n",
       "      <th>Construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3519</td>\n",
       "      <td>-99999</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>358.75</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>0.91820</td>\n",
       "      <td>9.842591</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3519</td>\n",
       "      <td>-99999</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>358.75</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>1.19412</td>\n",
       "      <td>7.487503</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3519</td>\n",
       "      <td>-99999</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>358.75</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>0.85836</td>\n",
       "      <td>5.800764</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3519</td>\n",
       "      <td>-99999</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>358.75</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>1.05932</td>\n",
       "      <td>6.581713</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3519</td>\n",
       "      <td>-99999</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>358.75</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>0.88016</td>\n",
       "      <td>10.083154</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID_1  OBJECTID  BASELINEID  TRANSORDER  PROCTIME  AUTOGEN     ENDX  \\\n",
       "0           1      3519      -99999           1  -99999.0   -99999 -99999.0   \n",
       "1           2      3519      -99999           1  -99999.0   -99999 -99999.0   \n",
       "2           3      3519      -99999           1  -99999.0   -99999 -99999.0   \n",
       "3           4      3519      -99999           1  -99999.0   -99999 -99999.0   \n",
       "4           5      3519      -99999           1  -99999.0   -99999 -99999.0   \n",
       "\n",
       "      ENDY  AZIMUTH  SHAPE_LENG      ...       Dist_MHWbay  SplitSort  \\\n",
       "0 -99999.0   358.75    -99999.0      ...          -99999.0          1   \n",
       "1 -99999.0   358.75    -99999.0      ...          -99999.0          2   \n",
       "2 -99999.0   358.75    -99999.0      ...          -99999.0          3   \n",
       "3 -99999.0   358.75    -99999.0      ...          -99999.0          4   \n",
       "4 -99999.0   358.75    -99999.0      ...          -99999.0          5   \n",
       "\n",
       "   DistSegDH  DistSegDL  DistSegArm   PointZ   PointSlp  Development  \\\n",
       "0   -99999.0   -99999.0    -99999.0  0.91820   9.842591          111   \n",
       "1   -99999.0   -99999.0    -99999.0  1.19412   7.487503          111   \n",
       "2   -99999.0   -99999.0    -99999.0  0.85836   5.800764          111   \n",
       "3   -99999.0   -99999.0    -99999.0  1.05932   6.581713          111   \n",
       "4   -99999.0   -99999.0    -99999.0  0.88016  10.083154          111   \n",
       "\n",
       "   Nourishment  Construction  \n",
       "0          111           111  \n",
       "1          111           111  \n",
       "2          111           111  \n",
       "3          111           111  \n",
       "4          111           111  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xltbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OBJECTID_1', 'OBJECTID', 'BASELINEID', 'TRANSORDER', 'PROCTIME',\n",
       "       'AUTOGEN', 'ENDX', 'ENDY', 'AZIMUTH', 'SHAPE_LENG', 'TRANSECTID', 'LRR',\n",
       "       'LR2', 'LSE', 'LCI90', 'TID2', 'LRR2', 'LR22', 'LSE2', 'LCI902',\n",
       "       'SL_Lon', 'SL_Lat', 'SL_easting', 'SL_northing', 'Bslope', 'Arm_Lon',\n",
       "       'Arm_Lat', 'Arm_easting', 'Arm_northing', 'Arm_z', 'DH_Lon', 'DH_Lat',\n",
       "       'DH_easting', 'DH_northing', 'DH_z', 'DL_Lon', 'DL_Lat', 'DL_easting',\n",
       "       'DL_northing', 'DL_z', 'DL_zMHW', 'DH_zMHW', 'Arm_zMHW', 'DistDH',\n",
       "       'DistDL', 'DistArm', 'Dist2Inlet', 'WidthLand', 'WidthFull',\n",
       "       'WidthPart', 'Source_beachwidth', 'MLW_easting', 'MLW_northing',\n",
       "       'beach_h_MLW', 'beachWidth_MLW', 'ORIG_OID', 'seg_y', 'seg_x',\n",
       "       'Dist_Seg', 'Dist_MHWbay', 'SplitSort', 'DistSegDH', 'DistSegDL',\n",
       "       'DistSegArm', 'PointZ', 'PointSlp', 'Development', 'Nourishment',\n",
       "       'Construction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xltbl.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join anthro data to transects\n",
    "\n",
    "1. Convert xls spreadsheet to points \n",
    "2. Select the first points along each transects and create new FC\n",
    "3. Spatial Join the new FC to the updated transects \n",
    "    - one to one\n",
    "    - keep all target features\n",
    "    - keep only the ID fields and the three anthro fields (and the transect fields [LRR, etc.]?)\n",
    "    - intersect\n",
    "\n",
    "4. Join the transect values to the pts based on sort_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_w_anthro = os.path.join(arcpy.env.workspace, 'fiis_trans_wAnthro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting feature class to array...\n",
      "Converting array to dataframe...\n"
     ]
    }
   ],
   "source": [
    "trans_df2 = fwa.FCtoDF(tr_w_anthro, id_fld=tID_fld, dffields=['Development', 'Nourishment','Construction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SplitSort</th>\n",
       "      <th>GeoSet</th>\n",
       "      <th>seg_x</th>\n",
       "      <th>seg_y</th>\n",
       "      <th>SubType</th>\n",
       "      <th>VegDens</th>\n",
       "      <th>VegType</th>\n",
       "      <th>ptSlp</th>\n",
       "      <th>ptZ</th>\n",
       "      <th>sort_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>ub_feat</th>\n",
       "      <th>Dist2Inlet</th>\n",
       "      <th>WidthFull</th>\n",
       "      <th>WidthLand</th>\n",
       "      <th>WidthPart</th>\n",
       "      <th>mean_Zmhw</th>\n",
       "      <th>max_Zmhw</th>\n",
       "      <th>Construction</th>\n",
       "      <th>Development</th>\n",
       "      <th>Nourishment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>642131.5400</td>\n",
       "      <td>4.498927e+06</td>\n",
       "      <td>4444.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.445196</td>\n",
       "      <td>0.68200</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>0.435538</td>\n",
       "      <td>0.81284</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>642133.1304</td>\n",
       "      <td>4.498932e+06</td>\n",
       "      <td>4444.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.445196</td>\n",
       "      <td>0.68200</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>0.435538</td>\n",
       "      <td>0.81284</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>642134.7209</td>\n",
       "      <td>4.498937e+06</td>\n",
       "      <td>4444.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.459952</td>\n",
       "      <td>0.39028</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>0.435538</td>\n",
       "      <td>0.81284</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>642115.6352</td>\n",
       "      <td>4.498880e+06</td>\n",
       "      <td>7777.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.083154</td>\n",
       "      <td>0.88016</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>0.435538</td>\n",
       "      <td>0.81284</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>642117.2257</td>\n",
       "      <td>4.498885e+06</td>\n",
       "      <td>4444.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.088981</td>\n",
       "      <td>0.86376</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>0.435538</td>\n",
       "      <td>0.81284</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SplitSort  GeoSet        seg_x         seg_y  SubType  VegDens  VegType  \\\n",
       "0          0     1.0  642131.5400  4.498927e+06   4444.0    111.0     11.0   \n",
       "1          1     1.0  642133.1304  4.498932e+06   4444.0    111.0     11.0   \n",
       "2          2     1.0  642134.7209  4.498937e+06   4444.0    111.0     11.0   \n",
       "3          3     2.0  642115.6352  4.498880e+06   7777.0    666.0     77.0   \n",
       "4          4     1.0  642117.2257  4.498885e+06   4444.0    111.0     11.0   \n",
       "\n",
       "       ptSlp      ptZ sort_ID     ...       ub_feat  Dist2Inlet  WidthFull  \\\n",
       "0   4.445196  0.68200       1     ...           NaN         NaN  65.098101   \n",
       "1   4.445196  0.68200       1     ...           NaN         NaN  65.098101   \n",
       "2   7.459952  0.39028       1     ...           NaN         NaN  65.098101   \n",
       "3  10.083154  0.88016       1     ...           NaN         NaN  65.098101   \n",
       "4  10.088981  0.86376       1     ...           NaN         NaN  65.098101   \n",
       "\n",
       "   WidthLand  WidthPart  mean_Zmhw  max_Zmhw  Construction  Development  \\\n",
       "0  65.098101  65.098101   0.435538   0.81284         111.0        111.0   \n",
       "1  65.098101  65.098101   0.435538   0.81284         111.0        111.0   \n",
       "2  65.098101  65.098101   0.435538   0.81284         111.0        111.0   \n",
       "3  65.098101  65.098101   0.435538   0.81284         111.0        111.0   \n",
       "4  65.098101  65.098101   0.435538   0.81284         111.0        111.0   \n",
       "\n",
       "   Nourishment  \n",
       "0        111.0  \n",
       "1        111.0  \n",
       "2        111.0  \n",
       "3        111.0  \n",
       "4        111.0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get existing DFs\n",
    "pts_df = pd.read_pickle(os.path.join(scratch_dir, transPts_null+'.pkl'))\n",
    "trans_df = pd.read_pickle(os.path.join(scratch_dir, extTrans_null+'.pkl'))\n",
    "\n",
    "# Join anthro fields to trans and points DFs\n",
    "trans_df = fun.join_columns(trans_df, trans_df2) \n",
    "pts_df = fun.join_columns(pts_df, trans_df, tID_fld)\n",
    "\n",
    "# Save dataframes to open elsewhere or later\n",
    "trans_df.to_pickle(os.path.join(scratch_dir, extTrans_null+'_anthro.pkl'))\n",
    "pts_df.to_pickle(os.path.join(scratch_dir, transPts_null+'_anthro.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SplitSort</th>\n",
       "      <th>seg_x</th>\n",
       "      <th>seg_y</th>\n",
       "      <th>Dist_Seg</th>\n",
       "      <th>Dist_MHWbay</th>\n",
       "      <th>DistSegDH</th>\n",
       "      <th>DistSegDL</th>\n",
       "      <th>DistSegArm</th>\n",
       "      <th>ptZ</th>\n",
       "      <th>ptSlp</th>\n",
       "      <th>...</th>\n",
       "      <th>WidthLand</th>\n",
       "      <th>WidthFull</th>\n",
       "      <th>uBW</th>\n",
       "      <th>uBH</th>\n",
       "      <th>ub_feat</th>\n",
       "      <th>mean_Zmhw</th>\n",
       "      <th>max_Zmhw</th>\n",
       "      <th>Construction</th>\n",
       "      <th>Development</th>\n",
       "      <th>Nourishment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66615</th>\n",
       "      <td>66615</td>\n",
       "      <td>677018.1595</td>\n",
       "      <td>4.509975e+06</td>\n",
       "      <td>230.000032</td>\n",
       "      <td>82.220969</td>\n",
       "      <td>143.009575</td>\n",
       "      <td>149.259519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60388</td>\n",
       "      <td>2.552202</td>\n",
       "      <td>...</td>\n",
       "      <td>312.221001</td>\n",
       "      <td>312.221001</td>\n",
       "      <td>80.787403</td>\n",
       "      <td>3.090523</td>\n",
       "      <td>DL</td>\n",
       "      <td>0.957232</td>\n",
       "      <td>4.469680</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85619</th>\n",
       "      <td>85619</td>\n",
       "      <td>687214.1370</td>\n",
       "      <td>4.514490e+06</td>\n",
       "      <td>345.696325</td>\n",
       "      <td>-131.024561</td>\n",
       "      <td>229.025318</td>\n",
       "      <td>240.263141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.35092</td>\n",
       "      <td>0.961539</td>\n",
       "      <td>...</td>\n",
       "      <td>749.924166</td>\n",
       "      <td>855.620515</td>\n",
       "      <td>105.471719</td>\n",
       "      <td>4.944896</td>\n",
       "      <td>DL</td>\n",
       "      <td>0.591762</td>\n",
       "      <td>7.122921</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66511</th>\n",
       "      <td>66511</td>\n",
       "      <td>677044.7910</td>\n",
       "      <td>4.509796e+06</td>\n",
       "      <td>55.000040</td>\n",
       "      <td>286.701757</td>\n",
       "      <td>32.017383</td>\n",
       "      <td>25.841729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.81084</td>\n",
       "      <td>2.832443</td>\n",
       "      <td>...</td>\n",
       "      <td>341.701797</td>\n",
       "      <td>341.701797</td>\n",
       "      <td>80.572297</td>\n",
       "      <td>2.878211</td>\n",
       "      <td>DL</td>\n",
       "      <td>0.657066</td>\n",
       "      <td>3.999680</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31938</th>\n",
       "      <td>31938</td>\n",
       "      <td>657490.3763</td>\n",
       "      <td>4.501733e+06</td>\n",
       "      <td>434.999996</td>\n",
       "      <td>137.250023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.76025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>572.250019</td>\n",
       "      <td>572.250019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.859720</td>\n",
       "      <td>111.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87919</th>\n",
       "      <td>87919</td>\n",
       "      <td>688190.4957</td>\n",
       "      <td>4.514639e+06</td>\n",
       "      <td>270.000020</td>\n",
       "      <td>275.964937</td>\n",
       "      <td>179.786747</td>\n",
       "      <td>188.534853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.43132</td>\n",
       "      <td>6.142564</td>\n",
       "      <td>...</td>\n",
       "      <td>545.964957</td>\n",
       "      <td>545.964957</td>\n",
       "      <td>81.470031</td>\n",
       "      <td>3.533009</td>\n",
       "      <td>DL</td>\n",
       "      <td>1.878405</td>\n",
       "      <td>5.923080</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SplitSort        seg_x         seg_y    Dist_Seg  Dist_MHWbay  \\\n",
       "66615      66615  677018.1595  4.509975e+06  230.000032    82.220969   \n",
       "85619      85619  687214.1370  4.514490e+06  345.696325  -131.024561   \n",
       "66511      66511  677044.7910  4.509796e+06   55.000040   286.701757   \n",
       "31938      31938  657490.3763  4.501733e+06  434.999996   137.250023   \n",
       "87919      87919  688190.4957  4.514639e+06  270.000020   275.964937   \n",
       "\n",
       "        DistSegDH   DistSegDL  DistSegArm      ptZ     ptSlp     ...       \\\n",
       "66615  143.009575  149.259519         NaN  0.60388  2.552202     ...        \n",
       "85619  229.025318  240.263141         NaN  0.35092  0.961539     ...        \n",
       "66511   32.017383   25.841729         NaN  1.81084  2.832443     ...        \n",
       "31938         NaN         NaN         NaN  0.76025       NaN     ...        \n",
       "87919  179.786747  188.534853         NaN  5.43132  6.142564     ...        \n",
       "\n",
       "        WidthLand   WidthFull         uBW       uBH ub_feat mean_Zmhw  \\\n",
       "66615  312.221001  312.221001   80.787403  3.090523      DL  0.957232   \n",
       "85619  749.924166  855.620515  105.471719  4.944896      DL  0.591762   \n",
       "66511  341.701797  341.701797   80.572297  2.878211      DL  0.657066   \n",
       "31938  572.250019  572.250019         NaN       NaN     NaN       NaN   \n",
       "87919  545.964957  545.964957   81.470031  3.533009      DL  1.878405   \n",
       "\n",
       "       max_Zmhw  Construction  Development  Nourishment  \n",
       "66615  4.469680         111.0        111.0        222.0  \n",
       "85619  7.122921         111.0        111.0        222.0  \n",
       "66511  3.999680         111.0        111.0        222.0  \n",
       "31938  3.859720         111.0        333.0        222.0  \n",
       "87919  5.923080         111.0        111.0        222.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recode the values for CSV\n",
    "pts_df4csv = pts_df.replace({'SubType': {7777:'{1111, 2222}', 1000:'{1111, 3333}'}, \n",
    "                              'VegType': {77:'{11, 22}', 88:'{22, 33}', 99:'{33, 44}'},\n",
    "                              'VegDens': {666: '{111, 222}', 777: '{222, 333}', \n",
    "                                          888: '{333, 444}', 999: '{222, 333, 444}'}})\n",
    "\n",
    "pts_df4csv.to_pickle(os.path.join(scratch_dir, transPts_null+'_4csv.pkl'))\n",
    "\n",
    "pts_df4csv.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: \\\\Mac\\stor\\Projects\\TransectExtraction\\FireIsland2012\\scratch\\FireIsland2012_transPts_fill.csv\n",
      "No Excel file created. You'll have to do it yourself from the CSV.\n"
     ]
    }
   ],
   "source": [
    "# pID_fld needs to be among the columns\n",
    "if not pID_fld in pts_df4csv.columns:\n",
    "    pts_df4csv.reset_index(drop=False, inplace=True)\n",
    "\n",
    "# Save CSV in scratch_dir\n",
    "csv_fname = os.path.join(scratch_dir, transPts_fill +'.csv')\n",
    "pts_df4csv.to_csv(os.path.join(scratch_dir, transPts_fill +'.csv'), na_rep=fill, index=False)\n",
    "print(\"OUTPUT: {}\".format(csv_fname))\n",
    "\n",
    "try:\n",
    "    xls_fname = os.path.join(scratch_dir, transPts_fill +'.xlsx')\n",
    "    pts_df4csv.to_excel(xls_fname, na_rep=fill, index=False)\n",
    "    print(\"OUTPUT: {}\".format(xls_fname))\n",
    "except:\n",
    "    print(\"No Excel file created. You'll have to do it yourself from the CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting feature class to array...\n",
      "Converting array to dataframe...\n"
     ]
    }
   ],
   "source": [
    "tr_w_LRR = os.path.join(arcpy.env.workspace, 'fiis_trans_wLRR')\n",
    "trans_df3 = fwa.FCtoDF(tr_w_LRR, id_fld=tID_fld, dffields=['LRR'])\n",
    "\n",
    "# Load dataframes\n",
    "trans_df= pd.read_pickle(os.path.join(scratch_dir, '20180108', extTrans_null+'_anthro.pkl'))\n",
    "pts_df= pd.read_pickle(os.path.join(scratch_dir, '20180108', transPts_null+'_anthro.pkl'))\n",
    "\n",
    "# Join anthro fields to trans and points DFs\n",
    "trans_df = fun.join_columns(trans_df, trans_df3) \n",
    "pts_df = fun.join_columns(pts_df, trans_df, tID_fld)\n",
    "\n",
    "# Save dataframes to open elsewhere or later\n",
    "trans_df.to_pickle(os.path.join(scratch_dir, extTrans_null+'_anthroLRR.pkl'))\n",
    "pts_df.to_pickle(os.path.join(scratch_dir, transPts_null+'_anthroLRR.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: \\\\Mac\\stor\\Projects\\TransectExtraction\\FireIsland2012\\scratch\\FireIsland2012_transPts_fill.csv\n"
     ]
    }
   ],
   "source": [
    "# Sort columns\n",
    "pts_df = pts_df.reindex_axis(sorted_pt_flds, axis=1)\n",
    "\n",
    "# Recode\n",
    "pts_df4csv = pts_df.replace({'GeoSet': {9999:-99999},\n",
    "                             'SubType': {7777:'{1111, 2222}', 1000:'{1111, 3333}', 9999:-99999}, \n",
    "                              'VegType': {77:'{11, 22}', 88:'{22, 33}', 99:'{33, 44}', 9999:-99999},\n",
    "                              'VegDens': {666: '{111, 222}', 777: '{222, 333}', \n",
    "                                          888: '{333, 444}', 999: '{222, 333, 444}', 9999:-99999}})\n",
    "\n",
    "# Save as pickle\n",
    "pts_df4csv.to_pickle(os.path.join(scratch_dir, transPts_null+'_4csv.pkl'))\n",
    "\n",
    "# Save as CSV\n",
    "csv_fname = os.path.join(scratch_dir, transPts_fill +'.csv')\n",
    "pts_df4csv.to_csv(os.path.join(scratch_dir, transPts_fill +'.csv'), na_rep=fill, index=False)\n",
    "print(\"OUTPUT: {}\".format(csv_fname))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing measure_Dist2Inlet() to work when shorelineXinlet intersect point falls directly on transect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site: Rockaway\n",
      "year: 2014\n",
      "Path to project directory (e.g. \\\\Mac\u000b",
      "olume\\dir\\FireIsland2014): \\\\Mac\\stor\\Projects\\TransectExtraction\\Rockaway2014\n",
      "setvars.py initialized variables.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arcpy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import core.functions_warcpy as fwa\n",
    "import core.functions as fun\n",
    "\n",
    "from core.setvars import *\n",
    "\n",
    "armorLines = os.path.join(home, 'BP_armorshoreward_2014')\n",
    "sl2trans_df = pd.read_pickle(os.path.join(scratch_dir, 'sl2trans.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Polyline object at 0xcee2240[0x1052ea58]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoreline = os.path.join(home, 'ShoreBetweenInlets')\n",
    "in_trans = extendedTrans = os.path.join(home, 'extTrans')\n",
    "inletLines = os.path.join(home, 'BP_inletLines_2014')\n",
    "tID_fld = 'sort_ID'\n",
    "\n",
    "# Calc Dist2Inlet in new dataframe \n",
    "# dist_df = fwa.measure_Dist2Inlet(shoreline, extendedTrans, inletLines, tID_fld)\n",
    "\n",
    "utmSR = arcpy.Describe(in_trans).spatialReference\n",
    "df = pd.DataFrame(columns=[tID_fld, 'Dist2Inlet']) # initialize dataframe\n",
    "inlets = [row[0] for row in arcpy.da.SearchCursor(inletLines, (\"SHAPE@\"))]\n",
    "\n",
    "cursor = arcpy.da.SearchCursor(shoreline, (\"SHAPE@\"))\n",
    "row = cursor.next()\n",
    "line = row[0]\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sort_ID</th>\n",
       "      <th>Dist2Inlet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>48.808948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>99.424597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>149.464110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>199.548346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>249.753352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.0</td>\n",
       "      <td>299.969340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.0</td>\n",
       "      <td>350.055564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.0</td>\n",
       "      <td>400.106897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.0</td>\n",
       "      <td>450.117768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.0</td>\n",
       "      <td>500.119950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.0</td>\n",
       "      <td>550.161641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17.0</td>\n",
       "      <td>600.247516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18.0</td>\n",
       "      <td>650.398649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19.0</td>\n",
       "      <td>700.584985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.0</td>\n",
       "      <td>751.188501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21.0</td>\n",
       "      <td>801.463322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22.0</td>\n",
       "      <td>851.579802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>23.0</td>\n",
       "      <td>901.656249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24.0</td>\n",
       "      <td>951.956104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1002.243656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1052.385953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1102.523397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>28.0</td>\n",
       "      <td>1152.709382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1202.731672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1253.919931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1304.221017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1354.235818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1404.255550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1454.271904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1504.367176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>320.0</td>\n",
       "      <td>1434.741675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>321.0</td>\n",
       "      <td>1398.802787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>322.0</td>\n",
       "      <td>1347.211720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>323.0</td>\n",
       "      <td>1296.706598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>324.0</td>\n",
       "      <td>1246.495805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>325.0</td>\n",
       "      <td>1196.372089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>326.0</td>\n",
       "      <td>1146.354271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>327.0</td>\n",
       "      <td>1096.334368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>328.0</td>\n",
       "      <td>1046.329747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>329.0</td>\n",
       "      <td>996.328387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>330.0</td>\n",
       "      <td>946.312956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>331.0</td>\n",
       "      <td>896.221888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>332.0</td>\n",
       "      <td>845.870218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>333.0</td>\n",
       "      <td>795.218353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>334.0</td>\n",
       "      <td>743.796029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>335.0</td>\n",
       "      <td>692.861819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>336.0</td>\n",
       "      <td>642.315287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>337.0</td>\n",
       "      <td>591.449390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>338.0</td>\n",
       "      <td>540.243316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>339.0</td>\n",
       "      <td>489.405724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>340.0</td>\n",
       "      <td>438.791766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>341.0</td>\n",
       "      <td>389.523890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>342.0</td>\n",
       "      <td>340.789207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>343.0</td>\n",
       "      <td>292.124316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>344.0</td>\n",
       "      <td>243.225999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>345.0</td>\n",
       "      <td>194.447230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>346.0</td>\n",
       "      <td>145.841662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>347.0</td>\n",
       "      <td>97.160504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>348.0</td>\n",
       "      <td>48.658929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>349.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sort_ID   Dist2Inlet\n",
       "0        6.0    48.808948\n",
       "1        7.0    99.424597\n",
       "2        8.0   149.464110\n",
       "3        9.0   199.548346\n",
       "4       10.0   249.753352\n",
       "5       11.0   299.969340\n",
       "6       12.0   350.055564\n",
       "7       13.0   400.106897\n",
       "8       14.0   450.117768\n",
       "9       15.0   500.119950\n",
       "10      16.0   550.161641\n",
       "11      17.0   600.247516\n",
       "12      18.0   650.398649\n",
       "13      19.0   700.584985\n",
       "14      20.0   751.188501\n",
       "15      21.0   801.463322\n",
       "16      22.0   851.579802\n",
       "17      23.0   901.656249\n",
       "18      24.0   951.956104\n",
       "19      25.0  1002.243656\n",
       "20      26.0  1052.385953\n",
       "21      27.0  1102.523397\n",
       "22      28.0  1152.709382\n",
       "23      29.0  1202.731672\n",
       "24      30.0  1253.919931\n",
       "25      31.0  1304.221017\n",
       "26      32.0  1354.235818\n",
       "27      33.0  1404.255550\n",
       "28      34.0  1454.271904\n",
       "29      35.0  1504.367176\n",
       "..       ...          ...\n",
       "314    320.0  1434.741675\n",
       "315    321.0  1398.802787\n",
       "316    322.0  1347.211720\n",
       "317    323.0  1296.706598\n",
       "318    324.0  1246.495805\n",
       "319    325.0  1196.372089\n",
       "320    326.0  1146.354271\n",
       "321    327.0  1096.334368\n",
       "322    328.0  1046.329747\n",
       "323    329.0   996.328387\n",
       "324    330.0   946.312956\n",
       "325    331.0   896.221888\n",
       "326    332.0   845.870218\n",
       "327    333.0   795.218353\n",
       "328    334.0   743.796029\n",
       "329    335.0   692.861819\n",
       "330    336.0   642.315287\n",
       "331    337.0   591.449390\n",
       "332    338.0   540.243316\n",
       "333    339.0   489.405724\n",
       "334    340.0   438.791766\n",
       "335    341.0   389.523890\n",
       "336    342.0   340.789207\n",
       "337    343.0   292.124316\n",
       "338    344.0   243.225999\n",
       "339    345.0   194.447230\n",
       "340    346.0   145.841662\n",
       "341    347.0    97.160504\n",
       "342    348.0    48.658929\n",
       "343    349.0     0.000000\n",
       "\n",
       "[344 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for [transect, tID] in arcpy.da.SearchCursor(in_trans, (\"SHAPE@\",  tID_fld)):\n",
    "    if not line.disjoint(transect):\n",
    "        # 1. cut shoreline at the transect\n",
    "        [rseg, lseg] = line.cut(transect)\n",
    "        # 2. if the shoreline segment touches any inlet, get the segment length. \n",
    "        #    If it doesn't touch an inlet, length is set to NaN to remove it from consideration.\n",
    "        # in case of multipart features, use only the first part\n",
    "        lenR = arcpy.Polyline(rseg.getPart(0), utmSR).length if not all(rseg.disjoint(i) for i in inlets) else np.nan\n",
    "        lenL = arcpy.Polyline(lseg.getPart(0), utmSR).length if not all(lseg.disjoint(i) for i in inlets) else np.nan\n",
    "        # 3. If shoreline and transect intersect on an inlet line, return 0 because transect is at an inlet.\n",
    "        #    Only check for overlap at segments that touch an inlet (not NaN).\n",
    "        xpt = line.intersect(transect, 1) # point where shoreline and transect intersect\n",
    "        lenR = 0 if not np.isnan(lenR) and not all(xpt.disjoint(i) for i in inlets) else lenR\n",
    "        lenL = 0 if not np.isnan(lenL) and not all(xpt.disjoint(i) for i in inlets) else lenL\n",
    "        mindist = np.nanmin([lenR, lenL])\n",
    "        df = df.append({tID_fld:tID, 'Dist2Inlet':mindist}, ignore_index=True)\n",
    "        try:\n",
    "            dist_prev = pd.to_numeric(df.loc[df[tID_fld]==tID-1, 'Dist2Inlet'])\n",
    "            if any(abs(dist_prev - mindist) > 300):\n",
    "                print(\"CAUTION: Large change in Dist2Inlet values between transects {} ({} m) and {} ({} m).\".format(tID-1, dist_prev, tID, mindist))\n",
    "        except:\n",
    "            print(\"Error-catching is not working in Dist2Inlet.\")\n",
    "            pass\n",
    "df\n",
    "\n",
    "# Looks good! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(lenR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n"
     ]
    }
   ],
   "source": [
    "for [transect, tID] in arcpy.da.SearchCursor(in_trans, (\"SHAPE@\",  tID_fld)):\n",
    "    if tID == 348:\n",
    "        break\n",
    "print(tID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17113.137653438618 48.65892948035971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.disjoint(transect)\n",
    "[rseg, lseg] = line.cut(transect) # rseg doesn't exist and length of lseg is 17161\n",
    "lenR = arcpy.Polyline(rseg.getPart(0), utmSR).length if not all(rseg.disjoint(i) for i in inlets) else np.nan\n",
    "lenL = arcpy.Polyline(lseg.getPart(0), utmSR).length if not all(lseg.disjoint(i) for i in inlets) else np.nan\n",
    "\n",
    "print(lenR, lenL)\n",
    "rseg.disjoint(transect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xpt = line.intersect(transect, 1) # where shoreline and transect intersect\n",
    "# is xpt the exact end of the shoreline and/or exactly on an inlet? better if it's on an inlet because the shoreline could end without an inlet\n",
    "# xpt.disjoint(inl)\n",
    "if not all(xpt.disjoint(i) for i in inlets):\n",
    "    print('winner?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for inl in inlets:\n",
    "    if not transect.disjoint(inl):\n",
    "        xpt = transect.intersect(inl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert CSV to FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path = r'\\\\Mac\\Home\\Downloads\\13CNT05_morphology'\n",
    "datapre = '14CNT01'\n",
    "path = os.path.join(proj_dir, 'Input_Data', '{}_morphology'.format(datapre), '{}_morphology.csv'.format(datapre))\n",
    "# fname = '{}_morphology.csv'.format(datapre)\n",
    "# dataname = os.path.splitext(fname)[0]\n",
    "fill = 999\n",
    "wgs84 = arcpy.SpatialReference(4326)\n",
    "state = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4683996"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import CSV as DF and remove nulls/fills\n",
    "df = pd.read_csv(path)\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4683996"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df != fill]\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "715212"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset to state \n",
    "df = df[df.state == state]\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238404"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset and convert to FC\n",
    "# dataname = os.path.splitext(fname)[0]+'_DT'\n",
    "df_dt = df[df.feature_type == 'DT']\n",
    "df_dt.to_csv(os.path.join(scratch_dir, '{}_DT_state{}.csv'.format(datapre, state)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result '\\\\\\\\Mac\\\\stor\\\\Projects\\\\DeepDive\\\\TransectExtraction\\\\Cobb2014\\\\scratch\\\\m14CNT01_DT_state16.shp'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DFtoFC throwing error \"table name is invalid [13CNT05_morphology_DT]\"\n",
    "fill = -99999\n",
    "fc = fwa.DFtoFC(df_dt, os.path.join(arcpy.env.scratchGDB, 'm{}_DT_state{}'.format(datapre, state)), spatial_ref=wgs84, xy=['lon', 'lat'], keep_fields='all', fill=fill)\n",
    "arcpy.FeatureClassToFeatureClass_conversion(fc, scratch_dir, 'm{}_DT_state{}.shp'.format(datapre, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# subset and convert to FC\n",
    "dataname = os.path.splitext(fname)[0]+'_DC'\n",
    "df_dc = df[df.feature_type == 'DC']\n",
    "df_dc.to_csv(os.path.join(path, '{}_ny_dhi.csv'.format(datapre)), index=False)\n",
    "\n",
    "fc = fwa.DFtoFC(df_dc, os.path.join(arcpy.env.scratchGDB, dataname), spatial_ref=wgs84, xy=['lon', 'lat'], keep_fields='all', fill=fill)\n",
    "arcpy.FeatureClassToFeatureClass_conversion(fc, path, dataname+'.shp')\n",
    "\n",
    "# subset and convert to FC\n",
    "dataname = os.path.splitext(fname)[0]+'_SL'\n",
    "df_sl = df[df.feature_type == 'SL'] \n",
    "df_sl.to_csv(os.path.join(path, '{}_ny_sl.csv'.format(datapre)), index=False)\n",
    "\n",
    "fc = fwa.DFtoFC(df_sl, os.path.join(arcpy.env.scratchGDB, dataname), spatial_ref=wgs84, xy=['lon', 'lat'], keep_fields='all', fill=fill)\n",
    "arcpy.FeatureClassToFeatureClass_conversion(fc, path, dataname+'.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... converting dataframe to array... \n",
      "... converting array to feature class... \n",
      "\n",
      "The projection of m14CNT01_morphology_s16_DT_wgs was changed. The new file is m14CNT01_morphology_s16_DT.\n",
      "... converting dataframe to array... \n",
      "... converting array to feature class... \n",
      "\n",
      "The projection of m14CNT01_morphology_s16_DC_wgs was changed. The new file is m14CNT01_morphology_s16_DC.\n",
      "... converting dataframe to array... \n",
      "... converting array to feature class... \n",
      "\n",
      "The projection of m14CNT01_morphology_s16_SL_wgs was changed. The new file is m14CNT01_morphology_s16_SL.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('\\\\\\\\Mac\\\\stor\\\\Projects\\\\DeepDive\\\\TransectExtraction\\\\Cobb2014\\\\scratch.gdb\\\\m14CNT01_morphology_s16_DT',\n",
       " '\\\\\\\\Mac\\\\stor\\\\Projects\\\\DeepDive\\\\TransectExtraction\\\\Cobb2014\\\\scratch.gdb\\\\m14CNT01_morphology_s16_DC',\n",
       " '\\\\\\\\Mac\\\\stor\\\\Projects\\\\DeepDive\\\\TransectExtraction\\\\Cobb2014\\\\scratch.gdb\\\\m14CNT01_morphology_s16_SL')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = r'\\\\Mac\\Home\\Downloads\\13CNT05_morphology'\n",
    "csvpath = os.path.join(proj_dir, 'Input_Data', '{}_morphology'.format(datapre), '{}_morphology.csv'.format(datapre))\n",
    "# fname = '{}_morphology.csv'.format(datapre)\n",
    "# dataname = os.path.splitext(fname)[0]\n",
    "\n",
    "state = 16\n",
    "\n",
    "def MorphologyCSV_to_FCsByFeature(csvpath, state, proj_code, csv_fill = 999, fc_fill = -99999, csv_epsg=4326):\n",
    "    # initialize\n",
    "    datapre = os.path.splitext(os.path.basename(csvpath))[0]\n",
    "    crs = arcpy.SpatialReference(csv_epsg)\n",
    "\n",
    "    # import CSV as DF \n",
    "    df = pd.read_csv(csvpath)\n",
    "\n",
    "    # remove nulls/fills\n",
    "    df = df[df != csv_fill]\n",
    "\n",
    "    # Subset by state\n",
    "    df = df[df.state == state]\n",
    "\n",
    "    # Subset by feature type\n",
    "    feat_code = 'DT'\n",
    "    subdf = df[df.feature_type == feat_code]\n",
    "    fcname = os.path.join(arcpy.env.scratchGDB, 'm{}_s{}_{}'.format(datapre, state, feat_code))\n",
    "    fc = fwa.DFtoFC(subdf, fcname+'_wgs', spatial_ref=crs, xy=['lon', 'lat'], keep_fields='all', fill=fc_fill)\n",
    "    dt_fc = fwa.ReProject(fc, fcname, proj_code)\n",
    "    # arcpy.SelectLayerByLocation_management(fcname, \"INTERSECT\", barrierBoundary)\n",
    "\n",
    "    feat_code = 'DC'\n",
    "    subdf = df[df.feature_type == feat_code]\n",
    "    fcname = os.path.join(arcpy.env.scratchGDB, 'm{}_s{}_{}'.format(datapre, state, feat_code))\n",
    "    fc = fwa.DFtoFC(subdf, fcname+'_wgs', spatial_ref=crs, xy=['lon', 'lat'], keep_fields='all', fill=fc_fill)\n",
    "    dc_fc = fwa.ReProject(fc, fcname, proj_code)\n",
    "\n",
    "    feat_code = 'SL'\n",
    "    subdf = df[df.feature_type == feat_code]\n",
    "    fcname = os.path.join(arcpy.env.scratchGDB, 'm{}_s{}_{}'.format(datapre, state, feat_code))\n",
    "    fc = fwa.DFtoFC(subdf, fcname+'_wgs', spatial_ref=crs, xy=['lon', 'lat'], keep_fields='all', fill=fc_fill)\n",
    "    sl_fc = fwa.ReProject(fc, fcname, proj_code)\n",
    "    \n",
    "    return(dt_fc, dc_fc, sl_fc)\n",
    "\n",
    "MorphologyCSV_to_FCsByFeature(csvpath, state, proj_code, csv_fill = 999, fc_fill = -99999, csv_epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'arcpy' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-183f70007fc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'arcpy' has no attribute '__version__'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
